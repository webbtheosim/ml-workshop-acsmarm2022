<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Day 1 Notebook Intro &mdash; acsmarm  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/mystnb.css" type="text/css" />
      <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script>let toggleHintShow = 'Click to show';</script>
        <script>let toggleHintHide = 'Click to hide';</script>
        <script>let toggleOpenOnPrint = 'true';</script>
        <script src="../_static/togglebutton.js"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
        <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Day 2" href="../20220602-crma/day2.html" />
    <link rel="prev" title="Day 1" href="day1.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../toc.html" class="icon icon-home"> acsmarm
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Materials for ML Workshops at ACS MARM: June 1-4, 2022</a></li>
<li class="toctree-l1"><a class="reference internal" href="day1.html">Day 1</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Day 1 Notebook Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="#initial-setup-of-python-environment">Initial Setup of Python Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="#activity-1-concepts-with-linear-regression">Activity 1: Concepts with Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#examining-a-human-hypothesis">Examining a human hypothesis</a></li>
<li class="toctree-l2"><a class="reference internal" href="#more-formal-optimization">More formal optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gradient-descent">Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="#linear-algebraic-solution">Linear algebraic solution</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-train-test-splits">Using train/test splits</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cross-validation">Cross-validation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#activity-2-chemical-data-basics">Activity 2: Chemical Data Basics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#dataset-exploration">Dataset Exploration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#summary-of-tasks">Summary of Tasks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#what-does-the-data-look-like">What does the data look like?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#feature-scaling">Feature scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-good-is-the-model">How good is the model?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#regularization">Regularization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#feature-selection">Feature Selection</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#activity-3-fun-with-neural-networks">Activity 3: Fun with Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#building-models-with-the-sequential-api">Building models with the Sequential API</a></li>
<li class="toctree-l2"><a class="reference internal" href="#building-models-with-functional-api">Building models with Functional API</a></li>
<li class="toctree-l2"><a class="reference internal" href="#return-of-the-solubility-dataset">Return of the Solubility Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#a-deep-neural-network-to-predict-solubility">A deep neural network to predict solubility</a></li>
<li class="toctree-l2"><a class="reference internal" href="#learning-curves">Learning curves</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../20220602-crma/day2.html">Day 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20220602-crma/activity1.html">Activity 1: Working with molecular data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20220602-crma/activity3.html">Activity 3: Implementing a graph convolutional neural network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20220603-applied/day3.html">Day 3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20220603-applied/notebook-a.html">Day 3 Notebook: Module A Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20220603-applied/notebook-a.html#setup-of-python-environment">Setup of Python Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20220603-applied/notebook-a.html#activity-1-understanding-gaussian-process-regression">Activity 1: Understanding Gaussian Process Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20220603-applied/notebook-a.html#team-activity-active-learning-challenge">Team Activity: Active Learning Challenge</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20220603-applied/notebook-b.html">Tutorial</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../toc.html">acsmarm</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../toc.html" class="icon icon-home"></a> &raquo;</li>
      <li>Day 1 Notebook Intro</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/webbtheosim/ml-workshop-acsmarm2022/blob/main/site/source/20220601-intro/notebook.ipynb" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="day-1-notebook-intro">
<h1>Day 1 Notebook Intro<a class="headerlink" href="#day-1-notebook-intro" title="Permalink to this headline"></a></h1>
</section>
<section id="initial-setup-of-python-environment">
<h1>Initial Setup of Python Environment<a class="headerlink" href="#initial-setup-of-python-environment" title="Permalink to this headline"></a></h1>
<p>Over the course of the next few days, we will rely on a number of python modules. Google Colaboratory comes equipped with a large number of these modules, but there are a few that we need that are not provided by default. Run the cells below to install these modules. You can optionally comment out modules that are only necessary for specific days that you will not be attending.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get non-default modules</span>
<span class="o">!</span>pip install rdkit-pypi
</pre></div>
</div>
</div>
</div>
</section>
<section id="activity-1-concepts-with-linear-regression">
<h1>Activity 1: Concepts with Linear Regression<a class="headerlink" href="#activity-1-concepts-with-linear-regression" title="Permalink to this headline"></a></h1>
<p>Many of the important concepts in supervised machine learning can be appreciated by a solid understanding of linear regression, which we all probably encountered early on – like elementary school. We are going to work through a linear regression task in a fashion  to appreciate many of the basic mechanics that underlie deep learning.</p>
<p>To start, we will pull a dataset generated in a recent paper that explores the use of machine learning to predict polymer properties. The label  that we extract (and our target for prediction) will be the radius of gyration (<span class="math notranslate nohighlight">\(R_g\)</span>), which provides a measure of an object’s size, for some simulated intrinsically disordered proteins.</p>
<p>A well known result from polymer physics is that <span class="math notranslate nohighlight">\(R_g \propto M^{0.5}\)</span>, where <span class="math notranslate nohighlight">\(M\)</span> is the number of some statistically uncorrelated sub-units in the polymer; the same result arises in the context of diffusion/random walks.</p>
<p>In the following, we will examine how well the data on <span class="math notranslate nohighlight">\(R_g\)</span> can be described by a simple linear model with <span class="math notranslate nohighlight">\(N^{0.5}\)</span> as our input feature (<span class="math notranslate nohighlight">\(N\)</span> will be the number of residues in the protein, which we do not generally expect to be a statistically uncorrelated sub-unit)</p>
<p>Run the cell below to obtain and view the data.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># modules for this activity</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span>     <span class="kn">import</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">,</span><span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span>  <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">KFold</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_raw_data</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">markeredgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Radius of Gyration (nm)&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;N^0.5&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">30</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>

<span class="n">url_for_labels</span>    <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/webbtheosim/featurization/main/Dataset_A/labels.csv&quot;</span>
<span class="n">url_for_sequences</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/webbtheosim/featurization/main/Dataset_A/sequences.txt&quot;</span>
<span class="n">idpdata</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">url_for_labels</span>
<span class="p">)</span>
<span class="n">idpdata</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">idpdata</span><span class="p">[</span><span class="s1">&#39;ROG (A)&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">/</span><span class="mf">10.</span>     <span class="c1"># these are now labels</span>

<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="n">seqs</span>  <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url_for_sequences</span><span class="p">)]</span>
<span class="n">X</span>     <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span> <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">seqs</span><span class="p">])</span><span class="o">**</span><span class="mf">0.5</span>   <span class="c1"># these are features</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_raw_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/2a44ed497ddc73f785a8f85034d542658e832b3ea186a78c07fce0550e10a8b2.png" src="../_images/2a44ed497ddc73f785a8f85034d542658e832b3ea186a78c07fce0550e10a8b2.png" />
</div>
</div>
<section id="examining-a-human-hypothesis">
<h2>Examining a human hypothesis<a class="headerlink" href="#examining-a-human-hypothesis" title="Permalink to this headline"></a></h2>
<p>At first glance, it certainly seems that there is reasonable linear correlation between our input and labels.</p>
<p>We are going to consider a function of the form</p>
<div class="math notranslate nohighlight">
\[R_g = \theta_0 + \theta_1 N^{0.5}\]</div>
<p>Can you look at the plot to “guess” values of these parameters? Complete the cell below and explore some “hypotheses”.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># basic set up</span>
<span class="n">Nmax</span> <span class="o">=</span> <span class="mi">900</span>
<span class="n">xline</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">Nmax</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">**</span><span class="mf">0.5</span>
<span class="n">f</span>    <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">th</span><span class="p">:</span> <span class="n">th</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">th</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x</span>

<span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>
<span class="c1"># fill in parameters</span>
<span class="n">thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">VALUE1</span><span class="p">,</span><span class="n">VALUE2</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span> <span class="c1"># this maps to a 2x1</span>
<span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>

<span class="c1"># make predictions using function</span>
<span class="n">yline</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">xline</span><span class="p">,</span><span class="n">thetas</span><span class="p">)</span>

<span class="c1"># examine hypothesis</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_raw_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xline</span><span class="p">,</span><span class="n">yline</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># make predictions from features and compute evaluation metrics</span>
<span class="n">yhat</span>  <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">thetas</span><span class="p">)</span>
<span class="n">r2</span>    <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">)</span>
<span class="n">rmse</span>  <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">)</span>
<span class="n">mae</span>   <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;r2 = </span><span class="si">{:&gt;5.3f}</span><span class="s2">, MSE = </span><span class="si">{:&gt;5.3f}</span><span class="s2">, MAE = </span><span class="si">{:&gt;5.3f}</span><span class="s2">&quot;</span>\
      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span><span class="n">rmse</span><span class="p">,</span><span class="n">mae</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="more-formal-optimization">
<h2>More formal optimization<a class="headerlink" href="#more-formal-optimization" title="Permalink to this headline"></a></h2>
<p>Probably your human-intuited fit yields a pretty darn good description of the data, but we’ll try to do better.</p>
<p>The ``training’’ of neural networks is really about <em>optimization</em> where the objective is to minimze a <em>loss</em> function that describes a disparity between the model predictions and the ground truth of some set of labels.</p>
<p>When we first encounter linear regression, our optimization is usually in the `least-squares’ sense; that is, our loss function is the mean-squared error over our observations. The problem of linear least-squares regression can be ``exactly’’ solved using techniques from linear algebra, but that is not so much the domain of machine learning. Therefore, we will approach a solution using gradient descent optimization, which is more akin to what is needed fro training a neural network.</p>
<p>Below we define and examine our loss function (a mean-squared error) over our parameter space (considering the whole dataset). We also place a star at the position of the hypothesis that we generated in the previous cell. Is it close to the minimum?</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">theta</span><span class="p">):</span>
  <span class="sd">&#39;&#39;&#39; Function to calculate cost function assuming a hypothesis of form y^ = X*theta</span>
<span class="sd">  Inputs:</span>
<span class="sd">  x = array of dependent variable</span>
<span class="sd">  y = array of training examples</span>
<span class="sd">  theta = array of parameters for hypothesis</span>

<span class="sd">  Returns:</span>
<span class="sd">  E = cost function</span>
<span class="sd">  &#39;&#39;&#39;</span>
  <span class="n">n</span>        <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1">#number of training examples</span>
  <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">)))</span> <span class="c1"># X </span>
  <span class="n">features</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:]</span>
  <span class="n">ypred</span> <span class="o">=</span> <span class="n">features</span><span class="nd">@theta</span> <span class="c1"># predictions with current hypothesis</span>
  <span class="n">E</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">ypred</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">y</span><span class="p">[:])</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">n</span> <span class="c1">#Cost function</span>
  <span class="k">return</span> <span class="n">E</span>

<span class="k">def</span> <span class="nf">plot_loss</span><span class="p">(</span><span class="n">t0</span><span class="p">,</span><span class="n">t1</span><span class="p">,</span><span class="n">E</span><span class="p">):</span>
  <span class="n">t0g</span><span class="p">,</span><span class="n">t1g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">t0</span><span class="p">,</span><span class="n">t1</span><span class="p">)</span>
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
  <span class="n">ax1</span>  <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
  <span class="n">surf</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">t0g</span><span class="p">,</span> <span class="n">t1g</span><span class="p">,</span> <span class="n">E</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">antialiased</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\theta_1$&quot;</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\theta_0$&quot;</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$E$&quot;</span><span class="p">)</span>
  <span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
  <span class="n">CS</span> <span class="o">=</span> <span class="n">ax2</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">t0g</span><span class="p">,</span><span class="n">t1g</span><span class="p">,</span><span class="n">E</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">25</span><span class="p">),</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\theta_0$&quot;</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\theta_1$&quot;</span><span class="p">)</span> 

  <span class="k">return</span> <span class="n">fig</span><span class="p">,</span><span class="n">ax1</span><span class="p">,</span><span class="n">ax2</span>

<span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>
<span class="c1">#Define grid over which to calculate J</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">theta0Rng</span> <span class="o">=</span> <span class="p">[</span><span class="n">AAA</span><span class="p">,</span><span class="n">BBB</span><span class="p">]</span>
<span class="n">theta1Rng</span> <span class="o">=</span> <span class="p">[</span><span class="n">CCC</span><span class="p">,</span><span class="n">DDD</span><span class="p">]</span>
<span class="n">theta0s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">theta0Rng</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">theta0Rng</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">N</span><span class="p">)</span>
<span class="n">theta1s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">theta1Rng</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">theta1Rng</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">N</span><span class="p">)</span>
<span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>


<span class="c1">#Initialize E as a matrix to store cost function values</span>
<span class="n">E</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">))</span>

<span class="c1"># Populate matrix</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">theta0</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">theta0s</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">j</span><span class="p">,</span><span class="n">theta1</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">theta1s</span><span class="p">):</span>
    <span class="n">theta_ij</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">theta0</span><span class="p">,</span><span class="n">theta1</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>
    <span class="n">E</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>   <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">theta_ij</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span><span class="n">ax1</span><span class="p">,</span><span class="n">ax2</span> <span class="o">=</span> <span class="n">plot_loss</span><span class="p">(</span><span class="n">theta0s</span><span class="p">,</span><span class="n">theta1s</span><span class="p">,</span><span class="n">E</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetas</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">thetas</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">,</span><span class="n">markersize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="gradient-descent">
<h2>Gradient Descent<a class="headerlink" href="#gradient-descent" title="Permalink to this headline"></a></h2>
<p>Next, we will implement gradient descent to find an optimal set of parameters. For this type of linear model, it is possible to obtain the requisite derivative of the loss function with respect to the parameters analytically. I have used that solution below.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">E2loss</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">yhat</span><span class="p">)[:]</span><span class="o">-</span><span class="n">y</span><span class="p">[:])</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">Grad_Descent</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">theta</span><span class="p">,</span><span class="n">alpha</span><span class="p">,</span><span class="n">nIters</span><span class="p">,</span><span class="n">x_te</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">y_te</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&#39;&#39;&#39;Gradient descent algorithm</span>
<span class="sd">  Inputs: </span>
<span class="sd">  x = dependent variable </span>
<span class="sd">  y = training data</span>
<span class="sd">  theta = parameters</span>
<span class="sd">  alpha = learning rate</span>
<span class="sd">  iters = number of iterations</span>
<span class="sd">  Output:</span>
<span class="sd">  theta = final parameters</span>
<span class="sd">  E = array of cost as a function of iterations</span>
<span class="sd">  &#39;&#39;&#39;</span>
  <span class="n">n</span>        <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1">#number of training examples</span>
  <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">)))</span>
  <span class="n">features</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:]</span>
  <span class="n">yhat</span>  <span class="o">=</span> <span class="n">features</span><span class="nd">@theta</span> <span class="c1"># predictions with current hypothesis</span>
  <span class="n">E_hist</span> <span class="o">=</span> <span class="p">[</span><span class="n">E2loss</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span><span class="n">y</span><span class="p">)]</span>

  <span class="k">if</span> <span class="n">x_te</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">E_hist_te</span> <span class="o">=</span> <span class="p">[</span><span class="n">E2loss</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x_te</span><span class="p">,</span><span class="n">theta</span><span class="p">),</span><span class="n">y_te</span><span class="p">)]</span>
    
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nIters</span><span class="p">):</span>
    <span class="n">e</span>     <span class="o">=</span> <span class="n">yhat</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">y</span><span class="p">[:]</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="p">(</span><span class="n">alpha</span><span class="o">*</span><span class="n">e</span><span class="p">[:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="nd">@features</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="c1">#</span>
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">features</span><span class="nd">@theta</span> <span class="c1"># predictions with current hypothesis</span>
    <span class="n">E_hist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">E2loss</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span><span class="n">y</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">x_te</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">E_hist_te</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">E2loss</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x_te</span><span class="p">,</span><span class="n">theta</span><span class="p">),</span><span class="n">y_te</span><span class="p">))</span>

  <span class="k">if</span> <span class="n">x_te</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">theta</span><span class="p">,</span><span class="n">E_hist</span><span class="p">,</span><span class="n">E_hist_te</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">theta</span><span class="p">,</span><span class="n">E_hist</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we’ll actually run the gradient descent code for a specified number of iterations and observe the outcome. We are also specifying a value of a ``learning’’ rate, which is a so-called hyperparmeter in our model training/optimization.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">th0</span>     <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.</span><span class="p">],[</span><span class="mf">.75</span><span class="p">]])</span>
<span class="n">nIters</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">thetaGD</span><span class="p">,</span> <span class="n">EGD</span> <span class="o">=</span> <span class="n">Grad_Descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">th0</span><span class="p">,</span><span class="mf">8e-6</span><span class="p">,</span><span class="n">nIters</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta_0 = </span><span class="si">{:&gt;8.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">thetaGD</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta_1 = </span><span class="si">{:&gt;8.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">thetaGD</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>

<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">nIters</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">EGD</span><span class="p">),</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Iterations&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># examine solution</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_raw_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xline</span><span class="p">,</span><span class="n">f</span><span class="p">(</span><span class="n">xline</span><span class="p">,</span><span class="n">thetaGD</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">r2</span>    <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">)</span>
<span class="n">mse</span>  <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">)</span>
<span class="n">mae</span>   <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;r2 = </span><span class="si">{:&gt;5.3f}</span><span class="s2">, MSE = </span><span class="si">{:&gt;8.5f}</span><span class="s2">, MAE = </span><span class="si">{:&gt;5.3f}</span><span class="s2">&quot;</span>\
      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span><span class="n">rmse</span><span class="p">,</span><span class="n">mae</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>theta_0 =  -0.0384
theta_1 =   0.2827
</pre></div>
</div>
<img alt="../_images/22baedb044f28df1f58fd49f46d6713c2ba1171ea363b840d833cca96f91b761.png" src="../_images/22baedb044f28df1f58fd49f46d6713c2ba1171ea363b840d833cca96f91b761.png" />
<img alt="../_images/205048a929f119629fd3a95f793c6c8526ef04fcc0e003e5588816d93918c2bb.png" src="../_images/205048a929f119629fd3a95f793c6c8526ef04fcc0e003e5588816d93918c2bb.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>r2 = 0.930, MSE =  0.08822, MAE = 0.162
</pre></div>
</div>
</div>
</div>
</section>
<section id="linear-algebraic-solution">
<h2>Linear algebraic solution<a class="headerlink" href="#linear-algebraic-solution" title="Permalink to this headline"></a></h2>
<p>If run for enough iterations, the solution obtained from gradient descent should outperform our human-intuited estimated model, even if just slightly. Because this is least-squares linear regression, we can also compare our solution with that obtained via linear algebra.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span><span class="p">,</span><span class="n">M</span><span class="p">))</span>
<span class="n">A</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:]</span>
<span class="n">thetaOpt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="nd">@A</span><span class="p">)</span><span class="nd">@A</span><span class="o">.</span><span class="n">T</span><span class="nd">@y</span>
<span class="c1">#thetOpt  = np.linalg.pinv(A)@y</span>
<span class="n">yhat</span>  <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">thetaOpt</span><span class="p">)</span>
<span class="n">r2</span>    <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">)</span>
<span class="n">mse</span>   <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">)</span>
<span class="n">mae</span>   <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta_0 = </span><span class="si">{:&gt;8.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">thetaOpt</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta_1 = </span><span class="si">{:&gt;8.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">thetaOpt</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;r2 = </span><span class="si">{:&gt;5.3f}</span><span class="s2">, MSE = </span><span class="si">{:&gt;8.5f}</span><span class="s2">, MAE = </span><span class="si">{:&gt;5.3f}</span><span class="s2">&quot;</span>\
      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span><span class="n">rmse</span><span class="p">,</span><span class="n">mae</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>theta_0 =  -0.0384
theta_1 =   0.2827
r2 = 0.941, MSE =  0.08822, MAE = 0.152
</pre></div>
</div>
</div>
</div>
</section>
<section id="using-train-test-splits">
<h2>Using train/test splits<a class="headerlink" href="#using-train-test-splits" title="Permalink to this headline"></a></h2>
<p>In our example so far, we did something, which is not generally good practice in machine learning: the data we used to train/optimize the model was the same data that we ultimately tested on. Because of the simplicity of the model that we have here, we are not at significant risk of overfitting, but it is better if we can assess the model using data that was held-out or unseen during training.</p>
<p>In the following cells, we will demonstrate the use of some convenient functions from scikit-learn that allow us to create a simple train/test split of our data.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create train vs. test split </span>
<span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>
<span class="c1"># write code to use the function train_test_split in scikit learn</span>
<span class="c1"># examine the shape of the output arrays and see how they compare</span>
<span class="c1"># to the original data structures X and y</span>
<span class="c1"># you will want to name the variables as follows</span>
<span class="c1"># X_tr --&gt; features for training data</span>
<span class="c1"># y_tr --&gt; labels for training data</span>
<span class="c1"># X_te --&gt; features for test data</span>
<span class="c1"># y_te --&gt; labels for test data</span>



<span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>



<span class="n">thetaGD</span><span class="p">,</span> <span class="n">E_tr</span><span class="p">,</span> <span class="n">E_te</span> <span class="o">=</span> <span class="n">Grad_Descent</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span><span class="n">y_tr</span><span class="p">,</span><span class="n">th0</span><span class="p">,</span><span class="mf">8e-6</span><span class="p">,</span><span class="n">nIters</span><span class="p">,</span><span class="n">X_te</span><span class="p">,</span><span class="n">y_te</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta_0 = </span><span class="si">{:&gt;8.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">thetaGD</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta_1 = </span><span class="si">{:&gt;8.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">thetaGD</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>

<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">nIters</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">E_tr</span><span class="p">),</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">nIters</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">E_te</span><span class="p">),</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Iterations&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># examine solution</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_raw_data</span><span class="p">(</span><span class="n">X_te</span><span class="p">,</span><span class="n">y_te</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xline</span><span class="p">,</span><span class="n">f</span><span class="p">(</span><span class="n">xline</span><span class="p">,</span><span class="n">thetaGD</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">X_te</span><span class="p">,</span><span class="n">thetaGD</span><span class="p">)</span>
<span class="n">r2</span>    <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span><span class="n">yhat</span><span class="p">)</span>
<span class="n">mse</span>  <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span><span class="n">yhat</span><span class="p">)</span>
<span class="n">mae</span>   <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span><span class="n">yhat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;r2 = </span><span class="si">{:&gt;5.3f}</span><span class="s2">, MSE = </span><span class="si">{:&gt;8.5f}</span><span class="s2">, MAE = </span><span class="si">{:&gt;5.3f}</span><span class="s2">&quot;</span>\
      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span><span class="n">rmse</span><span class="p">,</span><span class="n">mae</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cross-validation">
<h2>Cross-validation<a class="headerlink" href="#cross-validation" title="Permalink to this headline"></a></h2>
<p>An important consideration is how the choices that we make when constructing a model <em>impact</em> the model. Some of these choice may include things like hyperparameters associated with training (e.g., the number of training iterations and learning rate) or the actual constitution of our training data. If possible, we would like to mitigate any biases or deficiencies that we introduce in this fashion. Cross-validation provides one framework that can facililitate robustness with respect to the model training and our reporting of its results.</p>
<p>In the next cells, we will perform <span class="math notranslate nohighlight">\(k\)</span>-fold cross-validation to provide a better estimate of prospective model performance.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We will estimate the model accuracy using cross-validation</span>
<span class="n">k</span>     <span class="o">=</span> <span class="mi">10</span>
<span class="n">kf</span>    <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">r2s</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">k</span><span class="p">])</span>
<span class="n">mses</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">k</span><span class="p">])</span>
<span class="n">maes</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">k</span><span class="p">])</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">iTrain</span><span class="p">,</span><span class="n">iTest</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">y</span><span class="p">)):</span>
    <span class="n">Xi_tr</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">iTrain</span><span class="p">]</span>
    <span class="n">Xi_te</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">iTest</span><span class="p">]</span>
    <span class="n">yi_tr</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">iTrain</span><span class="p">]</span>
    <span class="n">yi_te</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">iTest</span><span class="p">]</span>
    <span class="n">thetaGD</span><span class="p">,</span> <span class="n">E_tr</span><span class="p">,</span> <span class="n">E_te</span> <span class="o">=</span> <span class="n">Grad_Descent</span><span class="p">(</span><span class="n">Xi_tr</span><span class="p">,</span><span class="n">yi_tr</span><span class="p">,</span><span class="n">th0</span><span class="p">,</span><span class="mf">8e-6</span><span class="p">,</span><span class="n">nIters</span><span class="p">,</span><span class="n">Xi_te</span><span class="p">,</span><span class="n">yi_te</span><span class="p">)</span>
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">Xi_te</span><span class="p">,</span><span class="n">thetaGD</span><span class="p">)</span>
    <span class="p">(</span><span class="n">r2s</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">mses</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">maes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">=</span> \
    <span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">yi_te</span><span class="p">,</span><span class="n">yhat</span><span class="p">),</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">yi_te</span><span class="p">,</span><span class="n">yhat</span><span class="p">),</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">yi_te</span><span class="p">,</span><span class="n">yhat</span><span class="p">))</span>

<span class="n">invsqrtk</span> <span class="o">=</span> <span class="mf">1.</span><span class="o">/</span><span class="n">k</span><span class="o">**</span><span class="mf">0.5</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;r2 = </span><span class="si">{:&gt;5.3f}</span><span class="s2"> +/- </span><span class="si">{:&gt;5.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">r2s</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">r2s</span><span class="p">,</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">invsqrtk</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mae= </span><span class="si">{:&gt;5.3f}</span><span class="s2"> +/- </span><span class="si">{:&gt;5.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mses</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mses</span><span class="p">,</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">invsqrtk</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mse= </span><span class="si">{:&gt;5.3f}</span><span class="s2"> +/- </span><span class="si">{:&gt;5.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">maes</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">maes</span><span class="p">,</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">invsqrtk</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>r2 = 0.941 +/- 0.003
mae= 0.075 +/- 0.006
mse= 0.152 +/- 0.004
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">rdkit</span><span class="o">,</span> <span class="nn">rdkit.Chem</span><span class="o">,</span> <span class="nn">rdkit.Chem.Draw</span>
<span class="kn">from</span> <span class="nn">rdkit.Chem.Draw</span> <span class="kn">import</span> <span class="n">IPythonConsole</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="n">IPythonConsole</span><span class="o">.</span><span class="n">ipython_useSVG</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="activity-2-chemical-data-basics">
<h1>Activity 2: Chemical Data Basics<a class="headerlink" href="#activity-2-chemical-data-basics" title="Permalink to this headline"></a></h1>
<p>In this activity, we will be working with a dataset on the aqueous solubility  of various molecules. Our main objective will be to construct and assess the performance of simple linear model for predicting solubility. Although linear modeling is not canonically machine learning, all the concepts and approaches we consider for treating/examining the data as well as evaluating the models will be transferable to building models based on deep learning algorithms.</p>
<p>Execute the following cell to import necessary modules and load the dataset. The data will be loaded into a Pandas dataframe named <code class="docutils literal notranslate"><span class="pre">soldata</span></code>. After, you can progress through the tasks as described.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the data from dmol-book</span>
<span class="n">soldata</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s2">&quot;https://github.com/whitead/dmol-book/raw/master/data/curated-solubility-dataset.csv&quot;</span>
<span class="p">)</span>
<span class="n">soldata</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-bbda20c2-119b-4df7-85c0-db17d4ac6a84">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Name</th>
      <th>InChI</th>
      <th>InChIKey</th>
      <th>SMILES</th>
      <th>Solubility</th>
      <th>SD</th>
      <th>Ocurrences</th>
      <th>Group</th>
      <th>MolWt</th>
      <th>...</th>
      <th>NumRotatableBonds</th>
      <th>NumValenceElectrons</th>
      <th>NumAromaticRings</th>
      <th>NumSaturatedRings</th>
      <th>NumAliphaticRings</th>
      <th>RingCount</th>
      <th>TPSA</th>
      <th>LabuteASA</th>
      <th>BalabanJ</th>
      <th>BertzCT</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A-3</td>
      <td>N,N,N-trimethyloctadecan-1-aminium bromide</td>
      <td>InChI=1S/C21H46N.BrH/c1-5-6-7-8-9-10-11-12-13-...</td>
      <td>SZEMGTQCPRNXEG-UHFFFAOYSA-M</td>
      <td>[Br-].CCCCCCCCCCCCCCCCCC[N+](C)(C)C</td>
      <td>-3.616127</td>
      <td>0.0</td>
      <td>1</td>
      <td>G1</td>
      <td>392.510</td>
      <td>...</td>
      <td>17.0</td>
      <td>142.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>158.520601</td>
      <td>0.000000e+00</td>
      <td>210.377334</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A-4</td>
      <td>Benzo[cd]indol-2(1H)-one</td>
      <td>InChI=1S/C11H7NO/c13-11-8-5-1-3-7-4-2-6-9(12-1...</td>
      <td>GPYLCFQEKPUWLD-UHFFFAOYSA-N</td>
      <td>O=C1Nc2cccc3cccc1c23</td>
      <td>-3.254767</td>
      <td>0.0</td>
      <td>1</td>
      <td>G1</td>
      <td>169.183</td>
      <td>...</td>
      <td>0.0</td>
      <td>62.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>29.10</td>
      <td>75.183563</td>
      <td>2.582996e+00</td>
      <td>511.229248</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A-5</td>
      <td>4-chlorobenzaldehyde</td>
      <td>InChI=1S/C7H5ClO/c8-7-3-1-6(5-9)2-4-7/h1-5H</td>
      <td>AVPYQKSLYISFPO-UHFFFAOYSA-N</td>
      <td>Clc1ccc(C=O)cc1</td>
      <td>-2.177078</td>
      <td>0.0</td>
      <td>1</td>
      <td>G1</td>
      <td>140.569</td>
      <td>...</td>
      <td>1.0</td>
      <td>46.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>17.07</td>
      <td>58.261134</td>
      <td>3.009782e+00</td>
      <td>202.661065</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A-8</td>
      <td>zinc bis[2-hydroxy-3,5-bis(1-phenylethyl)benzo...</td>
      <td>InChI=1S/2C23H22O3.Zn/c2*1-15(17-9-5-3-6-10-17...</td>
      <td>XTUPUYCJWKHGSW-UHFFFAOYSA-L</td>
      <td>[Zn++].CC(c1ccccc1)c2cc(C(C)c3ccccc3)c(O)c(c2)...</td>
      <td>-3.924409</td>
      <td>0.0</td>
      <td>1</td>
      <td>G1</td>
      <td>756.226</td>
      <td>...</td>
      <td>10.0</td>
      <td>264.0</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>6.0</td>
      <td>120.72</td>
      <td>323.755434</td>
      <td>2.322963e-07</td>
      <td>1964.648666</td>
    </tr>
    <tr>
      <th>4</th>
      <td>A-9</td>
      <td>4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...</td>
      <td>InChI=1S/C25H30N2O4/c1-5-20(26(10-22-14-28-22)...</td>
      <td>FAUAZXVRLVIARB-UHFFFAOYSA-N</td>
      <td>C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...</td>
      <td>-4.662065</td>
      <td>0.0</td>
      <td>1</td>
      <td>G1</td>
      <td>422.525</td>
      <td>...</td>
      <td>12.0</td>
      <td>164.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>6.0</td>
      <td>56.60</td>
      <td>183.183268</td>
      <td>1.084427e+00</td>
      <td>769.899934</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 26 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-bbda20c2-119b-4df7-85c0-db17d4ac6a84')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-bbda20c2-119b-4df7-85c0-db17d4ac6a84 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-bbda20c2-119b-4df7-85c0-db17d4ac6a84');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  </div></div>
</div>
<section id="dataset-exploration">
<h2>Dataset Exploration<a class="headerlink" href="#dataset-exploration" title="Permalink to this headline"></a></h2>
<p>One of the first things you should do for any ML task is simply get a feel for the data. As an end goal, we know we want to <em><strong>predict solubility</strong></em>. Thus, <em><strong>solubility</strong></em> is our <em><strong>label</strong></em> for a regression task, and we will try model this as a function of molecular descriptors of a molecule; these are used to construct prospective <em><strong>input feature vectors</strong></em> that represent the molecule.</p>
</section>
</section>
<section id="summary-of-tasks">
<h1>Summary of Tasks<a class="headerlink" href="#summary-of-tasks" title="Permalink to this headline"></a></h1>
<p>A. Take a moment to familiarize yourself with the modules that are imported in the previous cell. Then, look at the organization of the DataFrame, the first lines of which are shown above.</p>
<p>B. Plot the distribution of solubility values. Is there anything notable about its shape or range?</p>
<p>C. Examine pair correlations amongst possible input features. Are any descriptors highly correlated? How do the scale of the features compare?</p>
<section id="what-does-the-data-look-like">
<h2>What does the data look like?<a class="headerlink" href="#what-does-the-data-look-like" title="Permalink to this headline"></a></h2>
<p>Plot the distribution of solubility values. Is there anything notable about its shape or range?</p>
<p>Useful function: Useful function: sns.distplot
https://seaborn.pydata.org/generated/seaborn.distplot.html</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>


<span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/99ecfc3971d7795b45e5e0d94b42fedd1155629d77b7168ec1d24bbff20628ca.png" src="../_images/99ecfc3971d7795b45e5e0d94b42fedd1155629d77b7168ec1d24bbff20628ca.png" />
</div>
</div>
<p>Examine pair correlations amongst possible input features. Are any descriptors highly correlated? How do the scale of the features compare? What about correlation with the <em><strong>Solubility</strong></em>?</p>
<p>Useful function: sns.pairplot
https://seaborn.pydata.org/generated/seaborn.pairplot.html</p>
<p>Note that if you run pairplot over all features, it may take awhile to run. You may wish to only examine a subset for this reason.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">features_start_at</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">soldata</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;MolWt&quot;</span><span class="p">)</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">soldata</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">features_start_at</span><span class="p">:]</span>

<span class="c1"># code for pair correlations</span>
<span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>

<span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7324e9b3755ebfa4d3de92e69b0effd915606f292d03424cdf0a114587c51714.png" src="../_images/7324e9b3755ebfa4d3de92e69b0effd915606f292d03424cdf0a114587c51714.png" />
</div>
</div>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># code for looking at pair correlations with Solubility</span>
<span class="n">num_cols</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">num_rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)</span><span class="o">/</span> <span class="n">num_cols</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="n">num_rows</span><span class="p">,</span><span class="n">ncols</span><span class="o">=</span><span class="n">num_cols</span><span class="p">,</span><span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">feature_names</span><span class="p">):</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">soldata</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">soldata</span><span class="o">.</span><span class="n">Solubility</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">num_cols</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Solubility&quot;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> 
</pre></div>
</div>
</div>
</div>
</section>
<section id="feature-scaling">
<h2>Feature scaling<a class="headerlink" href="#feature-scaling" title="Permalink to this headline"></a></h2>
<p>Based on the disparate magnitudes of the possible features, we will perform a transformation of the input features to ensure everything has a similar “scale.”</p>
<p>We will use standard scaling here. Although I will not represent that this is the <em>best</em> choice for scaling, it is simple/safe to implement.</p>
<p>There are many scaling/transforming techniques available in packages like scikit-learn: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing</p>
</section>
<section id="how-good-is-the-model">
<h2>How good is the model?<a class="headerlink" href="#how-good-is-the-model" title="Permalink to this headline"></a></h2>
<p>Determine and evaluate the performance of a linear model. You can compare your results with that of the “exact” least-squares result afforded by linear algebra. You may wish to use the LinearRegression model from scikit-learn:
https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</p>
<div class="cell tag_hide-output tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># extract data set</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">soldata</span><span class="o">.</span><span class="n">Solubility</span><span class="p">[:])</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">soldata</span><span class="p">[</span><span class="n">feature_names</span><span class="p">])</span>
<span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span><span class="p">,</span><span class="n">M</span><span class="p">))</span>
<span class="n">A</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,:]</span>
<span class="c1">#thetaOpt = np.linalg.inv(A.T@A)@A.T@y </span>
<span class="n">thetaOpt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="nd">@y</span>
<span class="n">yhat</span>    <span class="o">=</span> <span class="n">A</span><span class="nd">@thetaOpt</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">markeredgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">,</span> <span class="n">adjustable</span><span class="o">=</span><span class="s1">&#39;box&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/c2765b12834b077f8c88c61a47ff8e749dfdadac694a70e6d3e835027c2b3f54.png" src="../_images/c2765b12834b077f8c88c61a47ff8e749dfdadac694a70e6d3e835027c2b3f54.png" />
</div>
</div>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span>  <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span>     <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">Lasso</span><span class="p">,</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span>          <span class="kn">import</span> <span class="n">r2_score</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span>    <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1"># We will estimate the model accuracy using cross-validation</span>
<span class="n">y</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">soldata</span><span class="o">.</span><span class="n">Solubility</span><span class="p">[:])</span>
<span class="n">X</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">soldata</span><span class="p">[</span><span class="n">feature_names</span><span class="p">])</span>
<span class="n">k</span>  <span class="o">=</span> <span class="mi">5</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">k</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">k</span><span class="p">])</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">colors</span> <span class="o">=</span>  <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Accent</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">)])</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">iTrain</span><span class="p">,</span><span class="n">iTest</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">y</span><span class="p">)):</span>
    <span class="n">Xi_tr</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">iTrain</span><span class="p">]</span>
    <span class="n">Xi_te</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">iTest</span><span class="p">]</span>
    <span class="n">yi_tr</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">iTrain</span><span class="p">]</span>
    <span class="n">yi_te</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">iTest</span><span class="p">]</span>

    <span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>
    <span class="c1"># perform feature scaling </span>

    <span class="c1"># create and test linear regression model</span>

    <span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>
    
    <span class="n">r2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">yi_te</span><span class="p">,</span><span class="n">yihat_te</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">yi_te</span><span class="p">,</span><span class="n">yihat_te</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">markeredgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">,</span> <span class="n">adjustable</span><span class="o">=</span><span class="s1">&#39;box&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">r2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="regularization">
<h2>Regularization<a class="headerlink" href="#regularization" title="Permalink to this headline"></a></h2>
<p>In the previous cells, we considered a model using all possible features, but earlier inspection of the data suggests that some of the features are highly correlated. The implication is that we might obtain a <em>simpler</em> model without any significant loss in accuracy were we to use a different set of features.</p>
<p>As a first pass towards something akin to feature selection, we will examine the impact of regularization on the model parameters. We discussed L1 and L2 regularization. Use the cells below to examine how using these regularization terms impacts the model parameters (i.e., coefficients). The use of L1 and L2 regularization is sometimes expressed as “Lasso” or “Ridge” regression respectively. There are implementations of these available on scikit-learn:</p>
<ul class="simple">
<li><p>https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html</p></li>
<li><p>https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html</p></li>
</ul>
<p>For simplicity, we will just use a simple train/test split. Examine the performance on the test set for the different methods and how this and the produced coefficients are impacted by the regularization weighting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set weight for regularization term</span>
<span class="n">my_alpha</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="c1"># create train vs. test split</span>
<span class="n">X_tr</span><span class="p">,</span> <span class="n">X_te</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># feature scaling (here using standard scaling)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">)</span>
<span class="n">X_tr_sc</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_tr</span><span class="p">)</span>

<span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>
<span class="c1"># create and test model with simple linear regression</span>
<span class="n">model_L0</span>  <span class="o">=</span> 
<span class="n">yhat_L0</span>   <span class="o">=</span> 
<span class="n">r2_L0</span>     <span class="o">=</span>

<span class="c1"># create and test model with L1 regularization</span>
<span class="n">model_L1</span>  <span class="o">=</span> 
<span class="n">yhat_L1</span>   <span class="o">=</span> 
<span class="n">r2_L1</span>     <span class="o">=</span> 

<span class="c1"># create and test model with L2 regularization</span>
<span class="n">model_L2</span>  <span class="o">=</span> 
<span class="n">yhat_L2</span>   <span class="o">=</span> 
<span class="n">r2_L2</span>     <span class="o">=</span> 
<span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>


<span class="c1"># plot and compare coefficients</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">colors</span> <span class="o">=</span>  <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Accent</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)])</span>
<span class="n">h</span>      <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)]</span>
<span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span><span class="n">model_L0</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span><span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">markeredgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;L0&#39;</span><span class="p">)</span>
<span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span><span class="n">model_L1</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;^&#39;</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span><span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">markeredgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;L1&#39;</span><span class="p">)</span>
<span class="n">h</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span><span class="n">model_L2</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span><span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">markeredgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;L2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span><span class="n">feature_names</span><span class="p">,</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="n">h</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Coefficients of determination are..&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;L0: </span><span class="si">{:&gt;8.3f}</span><span class="s2">, L1: </span><span class="si">{:&gt;8.3f}</span><span class="s2">, L2: </span><span class="si">{:&gt;8.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2_L0</span><span class="p">,</span><span class="n">r2_L1</span><span class="p">,</span><span class="n">r2_L2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d4d76bc818e2aa273811a0791f48e2ee40ec1a34846591e645d7138d77c15da5.png" src="../_images/d4d76bc818e2aa273811a0791f48e2ee40ec1a34846591e645d7138d77c15da5.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Coefficients of determination are..
L0:    0.468, L1:    0.420, L2:    0.467
</pre></div>
</div>
</div>
</div>
</section>
<section id="feature-selection">
<h2>Feature Selection<a class="headerlink" href="#feature-selection" title="Permalink to this headline"></a></h2>
<p>From previous results and analysis, we can probably conclude that we do not need all of the features for an accurate model. We mentioned a variety of feature selection methods. Here, we’ll use a simple greedy correlation filter to remove “redundant” features. Comment the code below between the indicated region to ensure comprehension. How does the result compare to any of the regularization methods? Does this make sense?</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>
<span class="n">rmax</span>        <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">subset</span>      <span class="o">=</span> <span class="p">[</span><span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">feature_names</span><span class="p">]</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
  <span class="n">absr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">soldata</span><span class="p">[</span><span class="n">subset</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;pearson&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
  <span class="n">np</span><span class="o">.</span><span class="n">fill_diagonal</span><span class="p">(</span><span class="n">absr</span><span class="p">,</span><span class="mf">0.</span><span class="p">)</span>
  <span class="n">imax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">absr</span><span class="p">)</span>
  <span class="n">jmax</span> <span class="o">=</span> <span class="n">imax</span><span class="o">%</span><span class="k">len</span>(subset)
  <span class="n">imax</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">imax</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">subset</span><span class="p">))</span>
  <span class="k">if</span> <span class="n">absr</span><span class="p">[</span><span class="n">imax</span><span class="p">,</span><span class="n">jmax</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">rmax</span><span class="p">:</span>
    <span class="k">break</span>
  <span class="n">rem_n</span> <span class="o">=</span> <span class="n">subset</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">jmax</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Removing feature </span><span class="si">{}</span><span class="s2"> with correlation of </span><span class="si">{:&gt;5.3f}</span><span class="s2"> with </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rem_n</span><span class="p">,</span><span class="n">absr</span><span class="p">[</span><span class="n">imax</span><span class="p">,</span><span class="n">jmax</span><span class="p">],</span><span class="n">subset</span><span class="p">[</span><span class="n">imax</span><span class="p">]))</span>
<span class="n">Xsub</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">soldata</span><span class="p">[</span><span class="n">subset</span><span class="p">])</span>
<span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>


<span class="c1"># create train vs. test split</span>
<span class="n">Xsub_tr</span><span class="p">,</span> <span class="n">Xsub_te</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">Xsub</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># feature scaling (here using standard scaling)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xsub_tr</span><span class="p">)</span>
<span class="n">Xsub_tr_sc</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xsub_tr</span><span class="p">)</span>

<span class="c1"># create and test model with simple linear regression</span>
<span class="n">model_L0</span>  <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xsub_tr_sc</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>
<span class="n">yhat_L0</span>   <span class="o">=</span> <span class="n">model_L0</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xsub_te</span><span class="p">))</span>
<span class="n">r2_L0</span>     <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span><span class="n">yhat_L0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">r2_L0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="activity-3-fun-with-neural-networks">
<h1>Activity 3: Fun with Neural Networks<a class="headerlink" href="#activity-3-fun-with-neural-networks" title="Permalink to this headline"></a></h1>
<p>In this activity session, we are going to use the Keras API to build simple, feed-forward deep neural networks. At the end, you will have some freedom to use the API to investigate the impact of hyperparameters and model complexity with the same solubility dataset.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>  <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span>       <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span><span class="n">Ridge</span><span class="p">,</span><span class="n">Lasso</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="nn">sklm</span>
<span class="kn">import</span> <span class="nn">pydot</span>
<span class="kn">import</span> <span class="nn">graphviz</span>
</pre></div>
</div>
</div>
</div>
<section id="building-models-with-the-sequential-api">
<h2>Building models with the Sequential API<a class="headerlink" href="#building-models-with-the-sequential-api" title="Permalink to this headline"></a></h2>
<p>We will start with the “sequential” model, which is really easy to use! You can play around with the different parameters and check the output with the .summary() method. <strong>Can you make sense of the number of parameters that are reported???</strong></p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create Model Container</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;myFirstModel&quot;</span><span class="p">)</span>

<span class="c1"># Define Layers</span>
<span class="n">inputLayer</span><span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,))</span>
<span class="n">layer1</span><span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;myFirstLayer&quot;</span><span class="p">)</span>
<span class="n">layer2</span><span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;oldNewsLayer&quot;</span><span class="p">)</span>
<span class="n">output</span><span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;outputLayer&quot;</span><span class="p">)</span>

<span class="c1"># Add layers to model</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">inputLayer</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layer1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layer2</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="c1"># Admire Model</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;myFirstModel&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 myFirstLayer (Dense)        (None, 10)                50        
                                                                 
 oldNewsLayer (Dense)        (None, 8)                 88        
                                                                 
 outputLayer (Dense)         (None, 1)                 9         
                                                                 
=================================================================
Total params: 147
Trainable params: 147
Non-trainable params: 0
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
</section>
<section id="building-models-with-functional-api">
<h2>Building models with Functional API<a class="headerlink" href="#building-models-with-functional-api" title="Permalink to this headline"></a></h2>
<p>We will also demonstrate the functional API. The functional API is more flexible than the Sequential API and permits you more control over the architecture. By contrast, <code class="docutils literal notranslate"><span class="pre">Sequential</span></code> models can only be fully connected, feed forward.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define Layers</span>
<span class="n">inputLayer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,))</span>
<span class="n">layer1</span><span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;myFirstLayer&quot;</span><span class="p">)</span>
<span class="n">layer2</span><span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;oldNewsLayer&quot;</span><span class="p">)</span>
<span class="n">output</span><span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">)</span>

<span class="c1"># Connect layers using &quot;layer calls&quot;</span>
<span class="c1"># we want to achieve</span>
<span class="c1"># inputLayer --&gt; layer1 --&gt; layer2 --&gt; outputs</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layer1</span><span class="p">(</span><span class="n">inputLayer</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">output</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Build model from inputs/outputs</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputLayer</span><span class="p">,</span><span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>\
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mySecondModel&quot;</span><span class="p">)</span>

<span class="c1"># Admire Model</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="s2">&quot;model.png&quot;</span><span class="p">,</span><span class="n">show_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;mySecondModel&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 4)]               0         
                                                                 
 myFirstLayer (Dense)        (None, 10)                50        
                                                                 
 oldNewsLayer (Dense)        (None, 8)                 88        
                                                                 
 output (Dense)              (None, 1)                 9         
                                                                 
=================================================================
Total params: 147
Trainable params: 147
Non-trainable params: 0
_________________________________________________________________
</pre></div>
</div>
<img alt="../_images/4bc51dd06d3062cb53e2e86b15b667726e1a3e4233ac5e0d850215400f7db4cd.png" src="../_images/4bc51dd06d3062cb53e2e86b15b667726e1a3e4233ac5e0d850215400f7db4cd.png" />
</div>
</div>
</section>
<section id="return-of-the-solubility-dataset">
<h2>Return of the Solubility Dataset<a class="headerlink" href="#return-of-the-solubility-dataset" title="Permalink to this headline"></a></h2>
<p>So, now we are going to try and apply what we have learned to create a neural network that can predict solubility from chemical descriptors of a molecule. <em>How many features are there to describe each molecule?</em></p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load and extract the data from dmol-book</span>
<span class="n">soldata</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s2">&quot;https://github.com/whitead/dmol-book/raw/master/data/curated-solubility-dataset.csv&quot;</span>
<span class="p">)</span>
<span class="n">features_start_at</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">soldata</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;MolWt&quot;</span><span class="p">)</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">soldata</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">features_start_at</span><span class="p">:]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">soldata</span><span class="o">.</span><span class="n">Solubility</span><span class="p">[:])</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span> 
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">soldata</span><span class="p">[</span><span class="n">feature_names</span><span class="p">])</span>
<span class="c1"># note the reshape on y above, which forces the structure to a matrix/2d array</span>
<span class="c1"># this is the form that will be expected by Keras</span>
<span class="c1"># the first index to an array corresponds to a specific example</span>
<span class="c1"># the size of the second index is the dimensionality</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="a-deep-neural-network-to-predict-solubility">
<h2>A deep neural network to predict solubility<a class="headerlink" href="#a-deep-neural-network-to-predict-solubility" title="Permalink to this headline"></a></h2>
<p>Use the cell below to build a neural network to predict solubility from the input features obtained from the .csv. Play around with the architecture to gain some intuition for the predictive capabilities of the network? How small of a network can you make that still yields “good” results (say, <span class="math notranslate nohighlight">\(r^2 &gt; 0.7\)</span>)?</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inScaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span> <span class="c1"># scaler for features</span>
<span class="n">outScaler</span><span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span> <span class="c1"># scaler for labels</span>
<span class="n">inScaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">outScaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">Xsc</span> <span class="o">=</span> <span class="n">inScaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># these are the scaled features</span>
<span class="n">ysc</span> <span class="o">=</span> <span class="n">outScaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1"># these are the scaled labels</span>

<span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>
<span class="n">model</span>  <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span> <span class="c1"># this initializes our simple model, but it doesn&#39;t have anhything in it!</span>
<span class="n">hidden1</span><span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span> <span class="c1"># here we create 20-neuron layer with relu activation</span>
<span class="n">hidden2</span><span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>  <span class="c1"># this is a 5-neuron layer, again with relu</span>
<span class="n">out</span>    <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>    <span class="c1"># we will only have one output, activation=None means linear/identity</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hidden1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hidden2</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">build</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span><span class="n">Xsc</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span> <span class="c1"># this last line specifies the input shape; there are lots of ways to do this</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="c1">#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$</span>
<span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="s2">&quot;model.png&quot;</span><span class="p">,</span><span class="n">show_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># now we compile the model and train it</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;SGD&quot;</span><span class="p">,</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mean_squared_error&quot;</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mean_absolute_error&quot;</span><span class="p">])</span>
<span class="n">hist</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">Xsc</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">ysc</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># make predictions</span>
<span class="n">ypredsc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xsc</span><span class="p">)</span> 
<span class="n">ypred</span>   <span class="o">=</span> <span class="n">outScaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">ypredsc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">ypred</span><span class="p">,</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">linearFit</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">ypred</span><span class="p">)</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">sklm</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">ypred</span><span class="p">)</span>
<span class="n">mae</span><span class="o">=</span> <span class="n">sklm</span><span class="o">.</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">ypred</span><span class="p">)</span>
<span class="n">mse</span><span class="o">=</span><span class="n">sklm</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">ypred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;r2 = </span><span class="si">{:&gt;5.2f}</span><span class="s2">, mae = </span><span class="si">{:&gt;5.2f}</span><span class="s2">, mse = </span><span class="si">{:&gt;5.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span><span class="n">mae</span><span class="p">,</span><span class="n">mse</span><span class="p">))</span>
<span class="n">xline</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">14</span><span class="p">],[</span><span class="mi">4</span><span class="p">]])</span>
<span class="n">yline</span> <span class="o">=</span> <span class="n">linearFit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xline</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xline</span><span class="p">,</span><span class="n">yline</span><span class="p">,</span><span class="s1">&#39;-r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xline</span><span class="p">,</span><span class="n">xline</span><span class="p">,</span><span class="s1">&#39;:k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential_1&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_3 (Dense)             (None, 32)                576       
                                                                 
 dense_4 (Dense)             (None, 5)                 165       
                                                                 
 dense_5 (Dense)             (None, 1)                 6         
                                                                 
=================================================================
Total params: 747
Trainable params: 747
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
250/250 [==============================] - 2s 5ms/step - loss: 0.6888 - mean_absolute_error: 0.6227 - val_loss: 0.3194 - val_mean_absolute_error: 0.4420
Epoch 2/100
250/250 [==============================] - 1s 3ms/step - loss: 0.4591 - mean_absolute_error: 0.4895 - val_loss: 0.2744 - val_mean_absolute_error: 0.4052
Epoch 3/100
250/250 [==============================] - 1s 3ms/step - loss: 0.4023 - mean_absolute_error: 0.4559 - val_loss: 0.2615 - val_mean_absolute_error: 0.3947
Epoch 4/100
250/250 [==============================] - 1s 3ms/step - loss: 0.3832 - mean_absolute_error: 0.4442 - val_loss: 0.2518 - val_mean_absolute_error: 0.3878
Epoch 5/100
250/250 [==============================] - 1s 3ms/step - loss: 0.3651 - mean_absolute_error: 0.4332 - val_loss: 0.2546 - val_mean_absolute_error: 0.3903
Epoch 6/100
250/250 [==============================] - 1s 3ms/step - loss: 0.3543 - mean_absolute_error: 0.4258 - val_loss: 0.2511 - val_mean_absolute_error: 0.3867
Epoch 7/100
250/250 [==============================] - 1s 3ms/step - loss: 0.3427 - mean_absolute_error: 0.4195 - val_loss: 0.2425 - val_mean_absolute_error: 0.3780
Epoch 8/100
250/250 [==============================] - 1s 3ms/step - loss: 0.3315 - mean_absolute_error: 0.4119 - val_loss: 0.2406 - val_mean_absolute_error: 0.3760
Epoch 9/100
250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - mean_absolute_error: 0.4072 - val_loss: 0.2512 - val_mean_absolute_error: 0.3821
Epoch 10/100
250/250 [==============================] - 1s 3ms/step - loss: 0.3163 - mean_absolute_error: 0.4018 - val_loss: 0.2447 - val_mean_absolute_error: 0.3793
Epoch 11/100
250/250 [==============================] - 1s 3ms/step - loss: 0.3111 - mean_absolute_error: 0.3991 - val_loss: 0.2480 - val_mean_absolute_error: 0.3801
Epoch 12/100
250/250 [==============================] - 1s 3ms/step - loss: 0.3065 - mean_absolute_error: 0.3962 - val_loss: 0.2418 - val_mean_absolute_error: 0.3780
Epoch 13/100
250/250 [==============================] - 1s 4ms/step - loss: 0.3019 - mean_absolute_error: 0.3921 - val_loss: 0.2411 - val_mean_absolute_error: 0.3765
Epoch 14/100
250/250 [==============================] - 1s 3ms/step - loss: 0.2986 - mean_absolute_error: 0.3902 - val_loss: 0.2343 - val_mean_absolute_error: 0.3752
Epoch 15/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2956 - mean_absolute_error: 0.3881 - val_loss: 0.2273 - val_mean_absolute_error: 0.3652
Epoch 16/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2917 - mean_absolute_error: 0.3857 - val_loss: 0.2302 - val_mean_absolute_error: 0.3698
Epoch 17/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2887 - mean_absolute_error: 0.3834 - val_loss: 0.2319 - val_mean_absolute_error: 0.3640
Epoch 18/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2879 - mean_absolute_error: 0.3842 - val_loss: 0.2425 - val_mean_absolute_error: 0.3774
Epoch 19/100
250/250 [==============================] - 1s 2ms/step - loss: 0.2877 - mean_absolute_error: 0.3835 - val_loss: 0.2364 - val_mean_absolute_error: 0.3711
Epoch 20/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2837 - mean_absolute_error: 0.3805 - val_loss: 0.2343 - val_mean_absolute_error: 0.3721
Epoch 21/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2817 - mean_absolute_error: 0.3792 - val_loss: 0.2420 - val_mean_absolute_error: 0.3781
Epoch 22/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2810 - mean_absolute_error: 0.3795 - val_loss: 0.2298 - val_mean_absolute_error: 0.3682
Epoch 23/100
250/250 [==============================] - 1s 2ms/step - loss: 0.2786 - mean_absolute_error: 0.3768 - val_loss: 0.2275 - val_mean_absolute_error: 0.3681
Epoch 24/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2778 - mean_absolute_error: 0.3761 - val_loss: 0.2148 - val_mean_absolute_error: 0.3563
Epoch 25/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2762 - mean_absolute_error: 0.3745 - val_loss: 0.2274 - val_mean_absolute_error: 0.3655
Epoch 26/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2748 - mean_absolute_error: 0.3736 - val_loss: 0.2214 - val_mean_absolute_error: 0.3608
Epoch 27/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2723 - mean_absolute_error: 0.3730 - val_loss: 0.2293 - val_mean_absolute_error: 0.3691
Epoch 28/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2713 - mean_absolute_error: 0.3725 - val_loss: 0.2239 - val_mean_absolute_error: 0.3608
Epoch 29/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2702 - mean_absolute_error: 0.3708 - val_loss: 0.2352 - val_mean_absolute_error: 0.3703
Epoch 30/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2697 - mean_absolute_error: 0.3704 - val_loss: 0.2387 - val_mean_absolute_error: 0.3741
Epoch 31/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2680 - mean_absolute_error: 0.3679 - val_loss: 0.2083 - val_mean_absolute_error: 0.3495
Epoch 32/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2684 - mean_absolute_error: 0.3703 - val_loss: 0.2209 - val_mean_absolute_error: 0.3587
Epoch 33/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2678 - mean_absolute_error: 0.3697 - val_loss: 0.2253 - val_mean_absolute_error: 0.3642
Epoch 34/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2668 - mean_absolute_error: 0.3682 - val_loss: 0.2241 - val_mean_absolute_error: 0.3660
Epoch 35/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2652 - mean_absolute_error: 0.3677 - val_loss: 0.2162 - val_mean_absolute_error: 0.3554
Epoch 36/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2663 - mean_absolute_error: 0.3674 - val_loss: 0.2280 - val_mean_absolute_error: 0.3647
Epoch 37/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2637 - mean_absolute_error: 0.3669 - val_loss: 0.2195 - val_mean_absolute_error: 0.3579
Epoch 38/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2627 - mean_absolute_error: 0.3661 - val_loss: 0.2368 - val_mean_absolute_error: 0.3739
Epoch 39/100
250/250 [==============================] - 1s 2ms/step - loss: 0.2628 - mean_absolute_error: 0.3652 - val_loss: 0.2157 - val_mean_absolute_error: 0.3548
Epoch 40/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2626 - mean_absolute_error: 0.3649 - val_loss: 0.2319 - val_mean_absolute_error: 0.3674
Epoch 41/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2615 - mean_absolute_error: 0.3653 - val_loss: 0.2284 - val_mean_absolute_error: 0.3626
Epoch 42/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2590 - mean_absolute_error: 0.3622 - val_loss: 0.2233 - val_mean_absolute_error: 0.3602
Epoch 43/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2602 - mean_absolute_error: 0.3627 - val_loss: 0.2642 - val_mean_absolute_error: 0.3834
Epoch 44/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2590 - mean_absolute_error: 0.3621 - val_loss: 0.2121 - val_mean_absolute_error: 0.3512
Epoch 45/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2590 - mean_absolute_error: 0.3635 - val_loss: 0.2398 - val_mean_absolute_error: 0.3697
Epoch 46/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2578 - mean_absolute_error: 0.3626 - val_loss: 0.2449 - val_mean_absolute_error: 0.3775
Epoch 47/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2573 - mean_absolute_error: 0.3620 - val_loss: 0.2142 - val_mean_absolute_error: 0.3531
Epoch 48/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2552 - mean_absolute_error: 0.3607 - val_loss: 0.2240 - val_mean_absolute_error: 0.3602
Epoch 49/100
250/250 [==============================] - 1s 2ms/step - loss: 0.2556 - mean_absolute_error: 0.3610 - val_loss: 0.2705 - val_mean_absolute_error: 0.3960
Epoch 50/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2567 - mean_absolute_error: 0.3612 - val_loss: 0.2111 - val_mean_absolute_error: 0.3514
Epoch 51/100
250/250 [==============================] - 1s 2ms/step - loss: 0.2557 - mean_absolute_error: 0.3602 - val_loss: 0.2363 - val_mean_absolute_error: 0.3672
Epoch 52/100
250/250 [==============================] - 1s 2ms/step - loss: 0.2565 - mean_absolute_error: 0.3612 - val_loss: 0.2318 - val_mean_absolute_error: 0.3637
Epoch 53/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2537 - mean_absolute_error: 0.3584 - val_loss: 0.2191 - val_mean_absolute_error: 0.3551
Epoch 54/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2534 - mean_absolute_error: 0.3588 - val_loss: 0.2344 - val_mean_absolute_error: 0.3685
Epoch 55/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2515 - mean_absolute_error: 0.3576 - val_loss: 0.2470 - val_mean_absolute_error: 0.3808
Epoch 56/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2530 - mean_absolute_error: 0.3589 - val_loss: 0.2216 - val_mean_absolute_error: 0.3572
Epoch 57/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2501 - mean_absolute_error: 0.3565 - val_loss: 0.2210 - val_mean_absolute_error: 0.3573
Epoch 58/100
250/250 [==============================] - 1s 2ms/step - loss: 0.2505 - mean_absolute_error: 0.3562 - val_loss: 0.2217 - val_mean_absolute_error: 0.3583
Epoch 59/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2509 - mean_absolute_error: 0.3570 - val_loss: 0.2056 - val_mean_absolute_error: 0.3445
Epoch 60/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2502 - mean_absolute_error: 0.3578 - val_loss: 0.2376 - val_mean_absolute_error: 0.3720
Epoch 61/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2507 - mean_absolute_error: 0.3574 - val_loss: 0.2092 - val_mean_absolute_error: 0.3479
Epoch 62/100
250/250 [==============================] - 1s 2ms/step - loss: 0.2482 - mean_absolute_error: 0.3552 - val_loss: 0.2179 - val_mean_absolute_error: 0.3542
Epoch 63/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2484 - mean_absolute_error: 0.3574 - val_loss: 0.2214 - val_mean_absolute_error: 0.3565
Epoch 64/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2492 - mean_absolute_error: 0.3550 - val_loss: 0.2079 - val_mean_absolute_error: 0.3474
Epoch 65/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2469 - mean_absolute_error: 0.3538 - val_loss: 0.2325 - val_mean_absolute_error: 0.3698
Epoch 66/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2469 - mean_absolute_error: 0.3541 - val_loss: 0.2408 - val_mean_absolute_error: 0.3778
Epoch 67/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2483 - mean_absolute_error: 0.3550 - val_loss: 0.2317 - val_mean_absolute_error: 0.3675
Epoch 68/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2459 - mean_absolute_error: 0.3528 - val_loss: 0.2124 - val_mean_absolute_error: 0.3504
Epoch 69/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2463 - mean_absolute_error: 0.3541 - val_loss: 0.2116 - val_mean_absolute_error: 0.3495
Epoch 70/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2467 - mean_absolute_error: 0.3535 - val_loss: 0.2291 - val_mean_absolute_error: 0.3637
Epoch 71/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2459 - mean_absolute_error: 0.3525 - val_loss: 0.2089 - val_mean_absolute_error: 0.3474
Epoch 72/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2437 - mean_absolute_error: 0.3524 - val_loss: 0.2181 - val_mean_absolute_error: 0.3551
Epoch 73/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2451 - mean_absolute_error: 0.3529 - val_loss: 0.2238 - val_mean_absolute_error: 0.3583
Epoch 74/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2475 - mean_absolute_error: 0.3540 - val_loss: 0.2638 - val_mean_absolute_error: 0.3934
Epoch 75/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2440 - mean_absolute_error: 0.3532 - val_loss: 0.2195 - val_mean_absolute_error: 0.3589
Epoch 76/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2427 - mean_absolute_error: 0.3518 - val_loss: 0.2029 - val_mean_absolute_error: 0.3423
Epoch 77/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2430 - mean_absolute_error: 0.3528 - val_loss: 0.2221 - val_mean_absolute_error: 0.3564
Epoch 78/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2439 - mean_absolute_error: 0.3535 - val_loss: 0.2201 - val_mean_absolute_error: 0.3561
Epoch 79/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2435 - mean_absolute_error: 0.3525 - val_loss: 0.2442 - val_mean_absolute_error: 0.3725
Epoch 80/100
250/250 [==============================] - 1s 2ms/step - loss: 0.2414 - mean_absolute_error: 0.3512 - val_loss: 0.2167 - val_mean_absolute_error: 0.3525
Epoch 81/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2421 - mean_absolute_error: 0.3517 - val_loss: 0.2300 - val_mean_absolute_error: 0.3627
Epoch 82/100
250/250 [==============================] - 1s 2ms/step - loss: 0.2412 - mean_absolute_error: 0.3508 - val_loss: 0.2063 - val_mean_absolute_error: 0.3461
Epoch 83/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2421 - mean_absolute_error: 0.3503 - val_loss: 0.2063 - val_mean_absolute_error: 0.3453
Epoch 84/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2412 - mean_absolute_error: 0.3510 - val_loss: 0.2233 - val_mean_absolute_error: 0.3578
Epoch 85/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2394 - mean_absolute_error: 0.3498 - val_loss: 0.2138 - val_mean_absolute_error: 0.3540
Epoch 86/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2419 - mean_absolute_error: 0.3512 - val_loss: 0.2221 - val_mean_absolute_error: 0.3574
Epoch 87/100
250/250 [==============================] - 1s 2ms/step - loss: 0.2406 - mean_absolute_error: 0.3495 - val_loss: 0.2574 - val_mean_absolute_error: 0.3823
Epoch 88/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2388 - mean_absolute_error: 0.3502 - val_loss: 0.2185 - val_mean_absolute_error: 0.3538
Epoch 89/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2400 - mean_absolute_error: 0.3495 - val_loss: 0.2208 - val_mean_absolute_error: 0.3569
Epoch 90/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2387 - mean_absolute_error: 0.3501 - val_loss: 0.2077 - val_mean_absolute_error: 0.3466
Epoch 91/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2393 - mean_absolute_error: 0.3490 - val_loss: 0.2122 - val_mean_absolute_error: 0.3505
Epoch 92/100
250/250 [==============================] - 1s 2ms/step - loss: 0.2385 - mean_absolute_error: 0.3492 - val_loss: 0.2171 - val_mean_absolute_error: 0.3542
Epoch 93/100
250/250 [==============================] - 1s 2ms/step - loss: 0.2377 - mean_absolute_error: 0.3477 - val_loss: 0.2249 - val_mean_absolute_error: 0.3613
Epoch 94/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2381 - mean_absolute_error: 0.3479 - val_loss: 0.2125 - val_mean_absolute_error: 0.3528
Epoch 95/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2380 - mean_absolute_error: 0.3480 - val_loss: 0.2355 - val_mean_absolute_error: 0.3675
Epoch 96/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2377 - mean_absolute_error: 0.3478 - val_loss: 0.2206 - val_mean_absolute_error: 0.3556
Epoch 97/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2371 - mean_absolute_error: 0.3471 - val_loss: 0.2095 - val_mean_absolute_error: 0.3482
Epoch 98/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2364 - mean_absolute_error: 0.3472 - val_loss: 0.2112 - val_mean_absolute_error: 0.3484
Epoch 99/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2374 - mean_absolute_error: 0.3478 - val_loss: 0.2249 - val_mean_absolute_error: 0.3636
Epoch 100/100
250/250 [==============================] - 0s 2ms/step - loss: 0.2362 - mean_absolute_error: 0.3469 - val_loss: 0.2171 - val_mean_absolute_error: 0.3577
r2 =  0.76, mae =  0.85, mse =  1.35
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x7fc5b550cc10&gt;]
</pre></div>
</div>
<img alt="../_images/e7e9c696ebfc24a2c64775ebfa1dbef527b4ef54ad3e81c889333b1f30582d8a.png" src="../_images/e7e9c696ebfc24a2c64775ebfa1dbef527b4ef54ad3e81c889333b1f30582d8a.png" />
</div>
</div>
</section>
<section id="learning-curves">
<h2>Learning curves<a class="headerlink" href="#learning-curves" title="Permalink to this headline"></a></h2>
<p>We can monitor the history of training and inspect it to get a sense of convergence/underfitting/overfitting during optimization. Do you think the current model is overfit?</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">hist</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">hist</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">hist</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="s1">&#39;-k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_loss</span><span class="p">,</span><span class="s1">&#39;:r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="day1.html" class="btn btn-neutral float-left" title="Day 1" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../20220602-crma/day2.html" class="btn btn-neutral float-right" title="Day 2" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Michael Webb, Andrew D White.
      <span class="lastupdated">Last updated on True.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>